<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visual Odometry Demo</title>
    <script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>
    <style>
        body { font-family: sans-serif; margin: 20px; }
        h1, h2 { text-align: center; }
        #videoUpload { display: block; margin: 10px auto 20px; }
        #toggleProcessingButton, #resetButton { display: inline-block; margin: 10px 5px 20px; padding: 10px 20px; font-size: 16px; }
        .button-container { text-align: center; } /* For centering buttons */
        .div_video_canvas_container { display: flex; justify-content: center; align-items: flex-start; gap: 20px; margin-bottom: 20px; flex-wrap: wrap; }
        #inputVideo { border: 1px solid black; }
        #outputCanvas { border: 1px solid black; }
        #poseData { background-color: #f0f0f0; border: 1px solid #ccc; padding: 10px; white-space: pre-wrap; }
        #3dPointsVis { text-align: center; }
        #3dPointsCanvas { border: 1px solid black; margin-top: 10px; }
        #statusMessages { text-align: center; margin-bottom: 10px; font-weight: bold; min-height: 1.2em; /* Prevent layout shift */ }
    </style>
</head>
<body>
    <h1>Visual Odometry Demo</h1>
    <div id="statusMessages" style="text-align: center; margin-bottom: 10px; font-weight: bold;">OpenCV loading...</div>

    <input type="file" id="videoUpload" accept="video/*">
    <div class="button-container">
        <button id="toggleProcessingButton">Start Processing</button>
        <button id="resetButton">Reset Application</button>
    </div>

    <div class="div_video_canvas_container">
        <video id="inputVideo" controls playsinline muted width="640"></video>
        <canvas id="outputCanvas"></canvas>
    </div>

    <h2>Camera Pose:</h2>
    <pre id="poseData">Rotation: N/A, Translation: N/A</pre>

    <h2>3D Points:</h2>
    <div id="3dPointsVis">
        <p>3D points visualization pending.</p>
        <canvas id="3dPointsCanvas"></canvas>
    </div>

<script>
    const videoUpload = document.getElementById('videoUpload');
    const inputVideo = document.getElementById('inputVideo');
    const outputCanvas = document.getElementById('outputCanvas');
    const poseDataEl = document.getElementById('poseData');
    const pointsCanvas = document.getElementById('3dPointsCanvas');
    const ctxOutput = outputCanvas.getContext('2d');
    const pointsCanvasCtx = pointsCanvas.getContext('2d');

    const toggleProcessingButton = document.getElementById('toggleProcessingButton');
    const statusMessages = document.getElementById('statusMessages'); // New
    const resetButton = document.getElementById('resetButton'); // New

    let processingActive = false;
    let orb, gray, keypoints, descriptors, noArray;
    let prevGray, prevKeypoints, prevDescriptors;
    let bfMatcher;
    let E, R, t, poseMask;
    let currentPose = { R: null, t: null, valid: false };
    let firstFrameProcessed = false;
    let K = null;
    let worldPoints = null;
    let accumulatedPoints = [];
    let frameCount = 0;

    function updateStatus(message) {
        if (statusMessages) {
            statusMessages.textContent = message;
        }
        console.log("Status: " + message);
    }

    cv.onRuntimeInitialized = () => {
        updateStatus("OpenCV.js is ready. Upload a video.");

        orb = new cv.ORB();
        gray = new cv.Mat();
        keypoints = new cv.KeyPointVector();
        descriptors = new cv.Mat();
        noArray = new cv.Mat();

        prevGray = new cv.Mat();
        prevKeypoints = new cv.KeyPointVector();
        prevDescriptors = new cv.Mat();

        bfMatcher = new cv.BFMatcher(cv.NORM_HAMMING, true);
        E = new cv.Mat(); R = new cv.Mat(); t = new cv.Mat(); poseMask = new cv.Mat();
        console.log("ORB, Matcher, and Mats initialized.");
    };

    videoUpload.addEventListener('change', function(e) {
        const file = e.target.files[0];
        if (file) {
            const url = URL.createObjectURL(file);
            inputVideo.src = url;
            updateStatus("Video selected. Loading metadata...");
            if (processingActive) {
                processingActive = false;
                toggleProcessingButton.textContent = 'Start Processing';
            }
            // Reset state for new video
            firstFrameProcessed = false;
            currentPose = { R: null, t: null, valid: false };
            poseDataEl.textContent = "Rotation: N/A, Translation: N/A";
            accumulatedPoints = [];
            frameCount = 0;
            if (pointsCanvasCtx) {
                pointsCanvasCtx.clearRect(0, 0, pointsCanvas.width, pointsCanvas.height);
                pointsCanvasCtx.fillStyle = "darkgrey";
                pointsCanvasCtx.fillRect(0, 0, pointsCanvas.width, pointsCanvas.height);
                pointsCanvasCtx.fillStyle = "white";
                pointsCanvasCtx.textAlign = "center";
                pointsCanvasCtx.fillText("3D points will appear here.", pointsCanvas.width / 2, pointsCanvas.height / 2);
            }
             if (ctxOutput) { // outputCanvas context
                ctxOutput.clearRect(0, 0, outputCanvas.width, outputCanvas.height);
                // Optional: Draw placeholder on outputCanvas too
                ctxOutput.fillStyle="grey"; ctxOutput.fillRect(0,0,outputCanvas.width,outputCanvas.height);
                ctxOutput.fillStyle="white"; ctxOutput.textAlign="center";
                ctxOutput.fillText("Upload video and press Start", outputCanvas.width/2, outputCanvas.height/2);
            }
        } else {
            updateStatus("Video selection cancelled.");
        }
    });

    inputVideo.addEventListener('loadedmetadata', function() {
        const w = inputVideo.videoWidth;
        const h = inputVideo.videoHeight;
        outputCanvas.width = w; outputCanvas.height = h;
        pointsCanvas.width = w; pointsCanvas.height = h / 2;

        const fx = w; const fy = w; const cx = w / 2; const cy = h / 2;
        if(K) K.delete(); // Delete previous K if it exists
        K = cv.matFromArray(3, 3, cv.CV_64F, [fx, 0, cx, 0, fy, cy, 0, 0, 1]);
        updateStatus("Video metadata loaded. Ready to process or select new video.");

        ctxOutput.clearRect(0, 0, outputCanvas.width, outputCanvas.height);
        ctxOutput.fillStyle = "grey"; ctxOutput.fillRect(0, 0, outputCanvas.width, outputCanvas.height);
        ctxOutput.fillStyle = "white"; ctxOutput.textAlign = "center";
        ctxOutput.fillText("Video loaded. Press 'Start Processing'.", outputCanvas.width / 2, outputCanvas.height / 2);

        pointsCanvasCtx.clearRect(0, 0, pointsCanvas.width, pointsCanvas.height);
        pointsCanvasCtx.fillStyle = "darkgrey"; pointsCanvasCtx.fillRect(0, 0, pointsCanvas.width, pointsCanvas.height);
        pointsCanvasCtx.fillStyle = "white"; pointsCanvasCtx.textAlign = "center";
        pointsCanvasCtx.fillText("3D points will appear here.", pointsCanvas.width / 2, pointsCanvas.height / 2);

        firstFrameProcessed = false; // Ensure reset if metadata reloads
    });

    function processFrame() {
        if (!processingActive || inputVideo.paused || inputVideo.ended) {
            if (processingActive) updateStatus("Processing stopped (video ended/paused).");
            return;
        }
        if (!K) {
            updateStatus("Waiting for K matrix (video metadata).");
            if (processingActive) requestAnimationFrame(processFrame);
            return;
        }
        frameCount++;
        // updateStatus(`Processing frame: ${frameCount}`); // This might be too noisy

        let currentFrameMat;
        try {
            ctxOutput.drawImage(inputVideo, 0, 0, outputCanvas.width, outputCanvas.height);
            currentFrameMat = cv.imread(outputCanvas);
            cv.cvtColor(currentFrameMat, gray, cv.COLOR_RGBA2GRAY);
            orb.detectAndCompute(gray, noArray, keypoints, descriptors);
        } catch (err) {
            console.error("Error in frame reading/feature detection:", err);
            updateStatus(`Error in frame ${frameCount}: ${err.message}. Stopping.`);
            processingActive = false;
            toggleProcessingButton.textContent = 'Start Processing';
            if(currentFrameMat && !currentFrameMat.isDeleted()) currentFrameMat.delete();
            return;
        }


        if (!firstFrameProcessed) {
            gray.copyTo(prevGray);
            if (prevKeypoints && !prevKeypoints.isDeleted()) prevKeypoints.delete();
            prevKeypoints = keypoints;
            descriptors.copyTo(prevDescriptors);
            firstFrameProcessed = true;
            updateStatus(`Frame ${frameCount}: First frame processed. Descriptors stored.`);

            ctxOutput.drawImage(inputVideo, 0, 0, outputCanvas.width, outputCanvas.height);
            for (let i = 0; i < keypoints.size(); i++) {
                const kp = keypoints.get(i); ctxOutput.fillStyle = "rgba(0, 255, 0, 0.7)";
                ctxOutput.beginPath(); ctxOutput.arc(kp.pt.x, kp.pt.y, 3, 0, 2*Math.PI); ctxOutput.fill();
            }
            currentFrameMat.delete();
            keypoints = new cv.KeyPointVector();
            descriptors = new cv.Mat();
            if (processingActive) requestAnimationFrame(processFrame);
            return;
        }

        if (prevDescriptors.empty() || descriptors.empty()) {
            updateStatus(`Frame ${frameCount}: Waiting for descriptors...`);
            gray.copyTo(prevGray);
            if (prevKeypoints && !prevKeypoints.isDeleted()) prevKeypoints.delete();
            prevKeypoints = keypoints;
            descriptors.copyTo(prevDescriptors);
            keypoints = new cv.KeyPointVector();
            descriptors = new cv.Mat();
            currentFrameMat.delete();
            if (processingActive) requestAnimationFrame(processFrame);
            return;
        }

        let matches = new cv.DMatchVectorVector();
        bfMatcher.knnMatch(descriptors, prevDescriptors, matches, 2);
        let good_matches = new cv.DMatchVector();
        const ratio_thresh = 0.75;
        for (let i = 0; i < matches.size(); ++i) {
            if (matches.get(i).size() > 1) {
                let m = matches.get(i).get(0); let n = matches.get(i).get(1);
                if (m.distance < ratio_thresh * n.distance) good_matches.push_back(m);
            }
        }

        const MIN_MATCHES = 10;
        if (good_matches.size() > MIN_MATCHES) {
            let points1_cv = []; let points2_cv = [];
            for (let i = 0; i < good_matches.size(); i++) {
                points1_cv.push(keypoints.get(good_matches.get(i).queryIdx).pt.x);
                points1_cv.push(keypoints.get(good_matches.get(i).queryIdx).pt.y);
                points2_cv.push(prevKeypoints.get(good_matches.get(i).trainIdx).pt.x);
                points2_cv.push(prevKeypoints.get(good_matches.get(i).trainIdx).pt.y);
            }

            let points1Mat = cv.matFromArray(points1_cv.length / 2, 1, cv.CV_32FC2, points1_cv);
            let points2Mat = cv.matFromArray(points2_cv.length / 2, 1, cv.CV_32FC2, points2_cv);

            E = cv.findEssentialMat(points1Mat, points2Mat, K, cv.RANSAC, 0.999, 1.0, poseMask); // poseMask is updated here

            if (!E.empty()) {
                let R_temp = new cv.Mat(); let t_temp = new cv.Mat(); let poseMask_temp = new cv.Mat(); // Use temp for recoverPose outputs
                let inlierCount = cv.recoverPose(E, points1Mat, points2Mat, K, R_temp, t_temp, poseMask_temp);

                if (inlierCount > MIN_MATCHES * 0.5) {
                    if(R && !R.isDeleted()) R.delete(); R = R_temp.clone(); R_temp.delete();
                    if(t && !t.isDeleted()) t.delete(); t = t_temp.clone(); t_temp.delete();
                    // poseMask from findEssentialMat is for points1Mat/points2Mat, poseMask_temp from recoverPose is for the same set of points but after E decomposition.
                    // We need poseMask_temp for filtering for triangulation if it's more restrictive or different.
                    // For simplicity, the provided code uses the global poseMask updated by findEssentialMat for filtering.
                    // However, it's safer to use the poseMask_temp that recoverPose returns for triangulation.
                    // Let's assume the global poseMask is what we want, or use poseMask_temp:
                    // if(poseMask && !poseMask.isDeleted()) poseMask.delete(); poseMask = poseMask_temp.clone(); poseMask_temp.delete();
                    // The prompt used global poseMask, so we stick to that for now. poseMask_temp.delete();
                    poseMask_temp.delete(); // Not using poseMask_temp from recoverPose further for now, as per prompt's logic.

                    poseDataEl.textContent = `R: [${R.data64F[0].toFixed(2)}, ..., ${R.data64F[8].toFixed(2)}]
t: [${t.data64F[0].toFixed(2)}, ${t.data64F[1].toFixed(2)}, ${t.data64F[2].toFixed(2)}]`;
                    if(currentPose.R && !currentPose.R.isDeleted()) currentPose.R.delete(); currentPose.R = R.clone();
                    if(currentPose.t && !currentPose.t.isDeleted()) currentPose.t.delete(); currentPose.t = t.clone();
                    currentPose.valid = true;

                    let P1 = new cv.Mat(3, 4, cv.CV_64F);
                    P1.data64F[0]=K.data64F[0]; P1.data64F[1]=0; P1.data64F[2]=K.data64F[2]; P1.data64F[3]=0;
                    P1.data64F[4]=0; P1.data64F[5]=K.data64F[4]; P1.data64F[6]=K.data64F[5]; P1.data64F[7]=0;
                    P1.data64F[8]=0; P1.data64F[9]=0; P1.data64F[10]=1; P1.data64F[11]=0;
                    let P2 = new cv.Mat(3, 4, cv.CV_64F); let Rt = new cv.Mat(3,4,cv.CV_64F);
                    for(let i=0;i<3;i++){for(let j=0;j<3;j++)Rt.data64F[i*4+j]=R.data64F[i*3+j]; Rt.data64F[i*4+3]=t.data64F[i];}
                    cv.gemm(K, Rt, 1, new cv.Mat(), 0, P2, 0);

                    // Use the global poseMask (from findEssentialMat) for filtering points for triangulation
                    let inlierCountForTriangulation = 0;
                    for(let i=0; i<poseMask.rows; ++i) if(poseMask.data[i] !== 0) inlierCountForTriangulation++;

                    let inlierPoints1_cvMat = new cv.Mat(inlierCountForTriangulation, 1, cv.CV_32FC2);
                    let inlierPoints2_cvMat = new cv.Mat(inlierCountForTriangulation, 1, cv.CV_32FC2);
                    let pt1C=0, pt2C=0;
                    for(let i=0;i<poseMask.rows;++i){if(poseMask.data[i]!==0){
                        inlierPoints1_cvMat.data32F[pt1C++]=points1Mat.data32F[i*2]; inlierPoints1_cvMat.data32F[pt1C++]=points1Mat.data32F[i*2+1];
                        inlierPoints2_cvMat.data32F[pt2C++]=points2Mat.data32F[i*2]; inlierPoints2_cvMat.data32F[pt2C++]=points2Mat.data32F[i*2+1];
                    }}

                    if (worldPoints && !worldPoints.isDeleted()) worldPoints.delete();
                    worldPoints = new cv.Mat();
                    if (inlierPoints1_cvMat.rows > 0) cv.triangulatePoints(P1, P2, inlierPoints1_cvMat, inlierPoints2_cvMat, worldPoints);

                    let tempPoints3D = [];
                    if (worldPoints.cols > 0) {
                        for (let i = 0; i < worldPoints.cols; ++i) {
                            let w = worldPoints.data32F[i*4+3];
                            if(Math.abs(w)>1e-4){let x=worldPoints.data32F[i*4]/w, y=worldPoints.data32F[i*4+1]/w, z=worldPoints.data32F[i*4+2]/w; if(z>0 && z<100)tempPoints3D.push({x:x,y:y,z:z});}
                        }
                    }
                    if(tempPoints3D.length > 0){
                        updateStatus(`Frame ${frameCount}: Pose OK. Found ${tempPoints3D.length} 3D points.`);
                        accumulatedPoints.push(...tempPoints3D.slice(0, Math.min(tempPoints3D.length, 20)));
                        if(accumulatedPoints.length > 200) accumulatedPoints.splice(0, accumulatedPoints.length - 200);
                    } else {
                        updateStatus(`Frame ${frameCount}: Pose OK. No new 3D points triangulated.`);
                    }
                    P1.delete(); P2.delete(); Rt.delete(); inlierPoints1_cvMat.delete(); inlierPoints2_cvMat.delete();
                } else {
                    updateStatus(`Frame ${frameCount}: Pose recovery failed (inliers: ${inlierCount}).`); currentPose.valid = false;
                    R_temp.delete(); t_temp.delete(); poseMask_temp.delete();
                }
            } else {
                updateStatus(`Frame ${frameCount}: Essential Matrix not found.`); currentPose.valid = false;
            }
            points1Mat.delete(); points2Mat.delete();
        } else {
            updateStatus(`Frame ${frameCount}: Not enough matches (${good_matches.size()}/${MIN_MATCHES}).`); currentPose.valid = false;
        }

        ctxOutput.drawImage(inputVideo, 0, 0, outputCanvas.width, outputCanvas.height);
        let kpColor = currentPose.valid ? "rgba(0,255,0,0.7)" : (good_matches.size()>=MIN_MATCHES ? "rgba(255,0,0,0.7)" : "rgba(255,165,0,0.7)");
        for (let i = 0; i < keypoints.size(); i++) {
            const kp = keypoints.get(i); ctxOutput.fillStyle = kpColor;
            ctxOutput.beginPath(); ctxOutput.arc(kp.pt.x, kp.pt.y, 3, 0, 2*Math.PI); ctxOutput.fill();
        }

        pointsCanvasCtx.clearRect(0,0,pointsCanvas.width,pointsCanvas.height);
        pointsCanvasCtx.fillStyle="darkgrey"; pointsCanvasCtx.fillRect(0,0,pointsCanvas.width,pointsCanvas.height);
        pointsCanvasCtx.fillStyle="yellow";
        for(const pt of accumulatedPoints){
            const scale=10; const x=pointsCanvas.width/2+pt.x*scale; const y=pointsCanvas.height/2-pt.y*scale;
            pointsCanvasCtx.beginPath(); pointsCanvasCtx.arc(x,y,2,0,2*Math.PI); pointsCanvasCtx.fill();
        }

        gray.copyTo(prevGray);
        if (prevKeypoints && !prevKeypoints.isDeleted()) prevKeypoints.delete();
        prevKeypoints = keypoints;
        descriptors.copyTo(prevDescriptors);
        keypoints = new cv.KeyPointVector();
        descriptors = new cv.Mat();

        matches.delete(); good_matches.delete(); currentFrameMat.delete();

        if (processingActive) requestAnimationFrame(processFrame);
        else updateStatus("Processing stopped.");
    }

    toggleProcessingButton.addEventListener('click', () => {
        if (!inputVideo.currentSrc && !inputVideo.srcObject) { // Simplified check if video is loaded
             updateStatus("Please upload a video first."); return;
        }
        if (!orb) { updateStatus("OpenCV not fully initialized. Please wait or reload."); return; }

        processingActive = !processingActive;
        if (processingActive) {
            toggleProcessingButton.textContent = 'Stop Processing';
            updateStatus("Processing starting...");
            frameCount = 0;
            firstFrameProcessed = false;
            if(currentPose.R && !currentPose.R.isDeleted()) currentPose.R.delete();
            if(currentPose.t && !currentPose.t.isDeleted()) currentPose.t.delete();
            currentPose = { R: null, t: null, valid: false };
            accumulatedPoints = [];
            poseDataEl.textContent = "Rotation: N/A, Translation: N/A";

            function safeDelete(mat) { if (mat && !mat.isDeleted()) mat.delete(); }
            safeDelete(keypoints); keypoints = new cv.KeyPointVector();
            safeDelete(descriptors); descriptors = new cv.Mat();
            safeDelete(prevKeypoints); prevKeypoints = new cv.KeyPointVector();
            safeDelete(prevDescriptors); prevDescriptors = new cv.Mat();

            requestAnimationFrame(processFrame);
        } else {
            toggleProcessingButton.textContent = 'Start Processing';
            updateStatus("Processing stopped by user.");
        }
    });

    resetButton.addEventListener('click', () => {
        updateStatus("Resetting application...");
        if (processingActive) {
            processingActive = false;
            toggleProcessingButton.textContent = 'Start Processing';
        }

        inputVideo.src = ''; inputVideo.srcObject = null;
        videoUpload.value = null;

        function safeDelete(mat) { if (mat && !mat.isDeleted()) mat.delete(); return null; }
        K = safeDelete(K);

        ctxOutput.clearRect(0,0,outputCanvas.width,outputCanvas.height);
        ctxOutput.fillStyle="grey"; ctxOutput.fillRect(0,0,outputCanvas.width,outputCanvas.height);
        ctxOutput.fillStyle="white"; ctxOutput.textAlign="center";
        ctxOutput.fillText("Output", outputCanvas.width/2, outputCanvas.height/2);

        pointsCanvasCtx.clearRect(0,0,pointsCanvas.width,pointsCanvas.height);
        pointsCanvasCtx.fillStyle="darkgrey"; pointsCanvasCtx.fillRect(0,0,pointsCanvas.width,pointsCanvas.height);
        pointsCanvasCtx.fillStyle="white"; pointsCanvasCtx.textAlign="center";
        pointsCanvasCtx.fillText("3D Points", pointsCanvas.width/2, pointsCanvas.height/2);

        poseDataEl.textContent = "Rotation: N/A, Translation: N/A";
        firstFrameProcessed = false;
        if(currentPose.R && !currentPose.R.isDeleted()) currentPose.R.delete();
        if(currentPose.t && !currentPose.t.isDeleted()) currentPose.t.delete();
        currentPose = { R: null, t: null, valid: false };
        accumulatedPoints = []; frameCount = 0;

        try {
            // Global Mats that persist across frames or processing sessions
            prevGray = safeDelete(prevGray); prevGray = new cv.Mat();
            prevKeypoints = safeDelete(prevKeypoints); prevKeypoints = new cv.KeyPointVector();
            prevDescriptors = safeDelete(prevDescriptors); prevDescriptors = new cv.Mat();
            keypoints = safeDelete(keypoints); keypoints = new cv.KeyPointVector(); // These are for current frame, but reset them
            descriptors = safeDelete(descriptors); descriptors = new cv.Mat();
            worldPoints = safeDelete(worldPoints); // worldPoints is a global Mat

            // Mats for pose calculation, reinitialized in onRuntimeInit or processFrame
            E = safeDelete(E); E = new cv.Mat();
            R = safeDelete(R); R = new cv.Mat();
            t = safeDelete(t); t = new cv.Mat();
            poseMask = safeDelete(poseMask); poseMask = new cv.Mat();
        } catch (e) { console.error("Error during OpenCV object reset:", e); }

        updateStatus("Application reset. Ready to upload a new video.");
    });

    window.addEventListener('beforeunload', () => {
        updateStatus("Cleaning up OpenCV objects...");
        function finalDelete(mat) { if (mat && !mat.isDeleted()) mat.delete(); }
        try {
            finalDelete(orb); finalDelete(gray); finalDelete(prevGray);
            finalDelete(keypoints); finalDelete(prevKeypoints);
            finalDelete(descriptors); finalDelete(prevDescriptors);
            finalDelete(bfMatcher);
            finalDelete(E); finalDelete(R); finalDelete(t); finalDelete(poseMask);
            finalDelete(K); finalDelete(noArray);
            finalDelete(worldPoints);
            if(currentPose.R) finalDelete(currentPose.R);
            if(currentPose.t) finalDelete(currentPose.t);
            console.log("OpenCV objects cleanup attempt complete.");
        } catch (e) { console.error("Error during final OpenCV cleanup:", e); }
    });
</script>
</body>
</html>
